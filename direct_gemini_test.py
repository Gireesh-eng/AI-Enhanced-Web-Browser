import os
import time
import google.generativeai as genai
from dotenv import load_dotenv

# Long sample text for testing summarization to encourage longer processing
LONG_TEXT = """
Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence
concerned with the interactions between computers and human language, in particular how to program computers
to process and analyze large amounts of natural language data. The goal is a computer capable of
"understanding" the contents of documents, including the contextual nuances of the language within them.
The technology can then accurately extract information and insights contained in the documents as well as
categorize and organize the documents themselves. Challenges in natural language processing frequently
involve speech recognition, natural language understanding, and natural language generation.

NLP has a wide range of applications in various fields. One of the most common applications is machine
translation, where systems like Google Translate or DeepL use NLP techniques to translate text from one
language to another. Another significant application is sentiment analysis, which involves determining
the sentiment expressed in a piece of text, whether it's positive, negative, or neutral. This is widely
used in social media monitoring, customer feedback analysis, and market research.

Information retrieval (IR) is also closely related to NLP. Search engines like Google and Bing use NLP
to understand user queries and retrieve relevant documents from the web. NLP techniques such as stemming,
lemmatization, and named entity recognition are crucial for effective IR. Furthermore, NLP powers
chatbots and virtual assistants like Siri, Alexa, and Google Assistant, enabling them to understand
user commands and respond in a human-like manner.

Text summarization, the task this test focuses on, is another key NLP application. It involves creating
a concise and fluent summary of a longer text document. This can be either extractive, where important
sentences are selected from the original text, or abstractive, where the summary is generated by
paraphrasing and rephrasing the original content. Abstractive summarization is more complex but often
produces more human-like summaries.

Other applications include text generation, question answering, speech recognition, and optical character
recognition. As the amount of textual data continues to grow exponentially, the importance of NLP and its
applications will only increase. Researchers are constantly working on developing more advanced NLP models,
often leveraging deep learning techniques, to tackle more complex language understanding and generation tasks.
The development of large language models (LLMs) like GPT-3 and BERT has marked a significant milestone
in the field, demonstrating remarkable capabilities in various NLP tasks. These models are trained on vast
amounts of text data and can generate coherent and contextually relevant text, translate languages, answer
questions, and much more with unprecedented accuracy. The ethical implications of such powerful technology
are also an active area of research and discussion.
""" * 10 # Make it very long to ensure it takes more than 30s if possible

def run_gemini_call():
    print("Starting direct Gemini API call...")
    load_dotenv(override=True)
    api_key = os.getenv("GEMINI_API_KEY")

    if not api_key or "your-api-key" in api_key.lower() or len(api_key) < 10:
        print(f"Error: Invalid or missing API key found: '{api_key}'. Please check your .env file.")
        return

    print(f"Using API Key: ...{api_key[-4:]}") # Print last 4 chars for verification

    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash') # Corrected model name

        prompt = f"Summarize the following text:\n\n{LONG_TEXT}"

        start_time = time.time()
        print(f"Generating content at {time.strftime('%H:%M:%S')}. Prompt length: {len(prompt)} chars.")
        
        # Set a client-side timeout for the request, e.g., 120 seconds
        # Note: The SDK might handle timeouts differently or have defaults.
        # This is an attempt to control it if the API call itself hangs indefinitely.
        # For google-generativeai, timeout is typically part of request_options in generate_content.
        request_options = {"timeout": 120} # 120 seconds

        response = model.generate_content(prompt, request_options=request_options)
        end_time = time.time()

        duration = end_time - start_time
        print(f"Content generated successfully at {time.strftime('%H:%M:%S')}.")
        print(f"API call duration: {duration:.2f} seconds.")

        if duration > 35: # Check if it took longer than the old QTimer timeout
            print("PRIMARY TEST INFO: API call duration was > 35s, indicating QTimer likely not active.")
        else:
            print("PRIMARY TEST INFO: API call duration was <= 35s. Test for QTimer absence is less conclusive from duration alone, but if no app-specific timeout message appears, it's a good sign.")
        
        if response and hasattr(response, 'text'):
            print(f"Summary (first 100 chars): {response.text[:100]}...")
        else:
            print("No response text received.")

    except Exception as e:
        end_time = time.time()
        duration = end_time - start_time
        print(f"An error occurred after {duration:.2f} seconds: {type(e).__name__} - {e}")
        if "API_KEY_INVALID" in str(e) or "API key" in str(e).lower() or "permission_denied" in str(e).lower() or "authentication" in str(e).lower():
            print("API KEY ERROR TEST: Detected an API key related error.")
        elif "deadline_exceeded" in str(e).lower() or "timeout" in str(e).lower():
            print(f"TIMEOUT INFO: A timeout occurred (likely from Google API client, not the old QTimer): {e}")
        else:
            print(f"OTHER ERROR: {e}")

if __name__ == '__main__':
    run_gemini_call()
